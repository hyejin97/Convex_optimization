{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SimpleNode.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gdbEWox7m67"
      },
      "source": [
        "# For Colab to use Tensorflow 2.X\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzLKjjRw8lxD"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58MuTwD_8nKr"
      },
      "source": [
        "class One_Feature_Node:\n",
        "  def __init__(self):\n",
        "    self.w = tf.Variable([[0.1]])\n",
        "    self.b = tf.Variable([[0.1]])\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.get_output(x)\n",
        "\n",
        "  def get_output(self, x):\n",
        "    out = tf.matmul(x, self.w)\n",
        "    out = tf.add(out, self.b)\n",
        "    out = tf.math.sigmoid(out)\n",
        "    return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PnXxyHz_5eX",
        "outputId": "675c023f-2c2a-44b0-cd3b-a0de5f2a14a3"
      },
      "source": [
        "x = tf.constant([[1.0]])\n",
        "\n",
        "one_feature_node = One_Feature_Node()\n",
        "one_feature_node(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.54983395]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIsCyt5UBVin"
      },
      "source": [
        "class Two_Feature_Node:\n",
        "  def __init__(self):\n",
        "    self.w = tf.Variable([[0.1], [0.2]])\n",
        "    self.b = tf.Variable([[0.1]])\n",
        "    \n",
        "  def __call__(self, x):\n",
        "    return self.get_output(x)\n",
        "  \n",
        "  def get_output(self, x):\n",
        "    out = tf.matmul(x, self.w) #can be done in O(1) even with the multiple data\n",
        "    out = tf.add(out, self.b)\n",
        "    out = tf.math.sigmoid(out)\n",
        "    return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWdRdd11MWtD"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9objosVLa4l",
        "outputId": "ff03a5e5-e160-46bc-8e89-8356b6db8ea1"
      },
      "source": [
        "#two features for one data\n",
        "x = tf.constant([[1.0, 2.0]])\n",
        "\n",
        "two_feature_node = Two_Feature_Node()\n",
        "two_feature_node(x)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[0.6456563]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csd7Fcc6GGEO",
        "outputId": "1e793148-0fb3-47a2-d6bd-1e36a07dc8ba"
      },
      "source": [
        "#multiple input data with two features\n",
        "x = tf.constant([[1.0, 2.0], [2.0, 3.0], [4.0, 5.0]])\n",
        "two_feature_node = Two_Feature_Node()\n",
        "two_feature_node(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
              "array([[0.6456563 ],\n",
              "       [0.7109495 ],\n",
              "       [0.81757444]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CizrBdmLrkTL"
      },
      "source": [
        "tf.random.set_seed(1)\n",
        "np.random.seed(1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4dW0YFzGDNM"
      },
      "source": [
        "class Node:\n",
        "  def __init__(self):\n",
        "    self.w = tf.Variable(tf.random.normal([2, 1]))\n",
        "    self.b = tf.Variable(tf.random.normal([1, 1]))\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.preds(x)\n",
        "  \n",
        "  def preds(self, x):\n",
        "    out = tf.matmul(x, self.w)\n",
        "    out = tf.add(out, self.b)\n",
        "    out = tf.nn.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "  def loss(self, y, y_pred): #loss function\n",
        "    return tf.reduce_mean(tf.square(y_pred - y))\n",
        "\n",
        "  def train(self, inputs, outputs, learning_rate):\n",
        "    epochs = range(10000)\n",
        "    for i, epoch in enumerate(epochs):\n",
        "      with tf.GradientTape() as t:\n",
        "        current_loss = self.loss(self.preds(inputs), outputs) #calculate loss\n",
        "        if i % 1000 == 0:\n",
        "          print(str(i) + \"th epoch, loss : \" + str(current_loss.numpy()))\n",
        "\n",
        "        #backpropagation\n",
        "        dw, db = t.gradient(current_loss, [self.w, self.b]) #calculate gradient\n",
        "        self.w.assign_sub((learning_rate * dw))\n",
        "        self.b.assign_sub((learning_rate * db))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS2sgf1XpUJf",
        "outputId": "7a1b3bc5-80af-4b1d-a58a-9c0cb432cf4a"
      },
      "source": [
        "#AND operation\n",
        "inputs = tf.constant([[0.0, 0.0], [0.0, 1.0], [1.0, 0.0], [1.0, 1.0]])\n",
        "outputs = tf.constant([[0.0], [0.0], [0.0], [1.0]])\n",
        "\n",
        "node = Node()\n",
        "node.train(inputs, outputs, 0.01)\n",
        "\n",
        "#test\n",
        "assert node([[0.0,0.0]]).numpy()[0][0] < 0.5\n",
        "assert node([[0.0,1.0]]).numpy()[0][0] < 0.5\n",
        "assert node([[1.0,0.0]]).numpy()[0][0] < 0.5\n",
        "assert node([[1.0,1.0]]).numpy()[0][0] >= 0.5"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0th epoch, loss : 0.17513402\n",
            "1000th epoch, loss : 0.08886799\n",
            "2000th epoch, loss : 0.071351275\n",
            "3000th epoch, loss : 0.06387137\n",
            "4000th epoch, loss : 0.05824548\n",
            "5000th epoch, loss : 0.053707756\n",
            "6000th epoch, loss : 0.049904104\n",
            "7000th epoch, loss : 0.04662943\n",
            "8000th epoch, loss : 0.043757536\n",
            "9000th epoch, loss : 0.041206293\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}